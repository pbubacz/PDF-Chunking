{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME=\"sample-text.txt\"\n",
    "with open(FILE_NAME, \"r\", encoding=\"utf-8\") as file:\n",
    "        text=file.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character splitting \n",
    "\n",
    "Key Concepts:\n",
    "\n",
    "- **Chunk Size**: This is the number of characters you want each chunk to contain. It can be any number, such as 50, 100, or even 100,000 characters.\n",
    "\n",
    "- **Chunk Overlap**: This refers to the number of characters that overlap between consecutive chunks. Overlapping helps to prevent splitting a single context into multiple pieces, although it does introduce some redundancy across chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size = 50, chunk_overlap=0, separator='', strip_whitespace=False)\n",
    "text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size = 50, chunk_overlap=10, separator='me', strip_whitespace=False)\n",
    "text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Character Text Splitter\n",
    "\n",
    "#### Default Separators in LangChain:\n",
    "\n",
    "- `\"\\n\\n\"`: Double new line, commonly indicating paragraph breaks.\n",
    "- `\"\\n\"`: Single new line.\n",
    "- `\" \"`: Spaces between words.\n",
    "- `\"\"`: Individual characters.\n",
    "\n",
    "Period (`\".\"`) is not included in the default list of separators. This is because periods are often used in abbreviations and numbers, and splitting on periods can lead to incorrect chunking. However, you can add periods to the list of separators if you want to split on periods as well.\n",
    "After splitting the text into paragraphs, the process evaluates the size of each chunk. If a chunk is too large, it will attempt to divide it using the next available separator. Should the chunk remain too large, the process will continue to the subsequent separator, repeating this until an appropriate size is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 50, chunk_overlap=0)\n",
    "text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 550, chunk_overlap=0)\n",
    "text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specialized Chunking\n",
    "\n",
    "For Markdown, Python, and JavaScript files, the splitters will resemble the Recursive Character method but will use different separators tailored to each format.\n",
    "\n",
    "##### Markdown Splitter\n",
    "Markdown files often contain headings, lists, code blocks, and links. A specialized splitter can use these elements as natural breakpoints.\n",
    "\n",
    "- **Headings**: Split at `#`, `##`, `###`, etc.\n",
    "- **Lists**: Split at `-`, `*`, `1.`, etc.\n",
    "- **Code Blocks**: Split at triple backticks ``` ````\n",
    "- **Links**: Split at `[text](url)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    return len(encoding.encode(string))\n",
    "\n",
    "def print_chunks_page_content(page_content,sparse=False):\n",
    "    print(f\"Number of chunks: {len(page_content)}\")\n",
    "    for i, chunk in enumerate(page_content):\n",
    "        print(f\"Chunk {i + 1} character count: {len(chunk.page_content)} token number: {num_tokens_from_string(chunk.page_content)}\" )\n",
    "        if not sparse:\n",
    "            print(chunk.page_content)        \n",
    "        else:\n",
    "            print(chunk.page_content [:50])\n",
    "        print(\"Meta data: \", chunk.metadata)\n",
    "        print()\n",
    "\n",
    "MD_FILE_NAME=\"sample-markdown.md\"\n",
    "with open(MD_FILE_NAME, \"r\", encoding=\"utf-8\") as file:\n",
    "        markdown_txt=file.read()\n",
    "print(markdown_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "splitter = MarkdownTextSplitter(chunk_size = 500, chunk_overlap=0)\n",
    "md_splits=splitter.create_documents([markdown_txt])\n",
    "print(\"Length of splits: \" + str(len(md_splits)))\n",
    "print_chunks_page_content(md_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use MarkdownHeaderTextSplitter to split the text into chunks based on the headings in the text. This will allow us to analyze the text in smaller, more manageable pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"####\", \"Header 4\"),\n",
    "    (\"#####\", \"Header 5\"),\n",
    "    (\"######\", \"Header 6\"),  \n",
    "    (\"#######\", \"Header 7\"), \n",
    "    (\"########\", \"Header 8\")\n",
    "]\n",
    "md_text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
    "md_header_splits = md_text_splitter.split_text(markdown_txt)\n",
    "\n",
    "print(\"Length of splits: \" + str(len(md_header_splits)))\n",
    "print_chunks_page_content(md_header_splits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
